
<html>
<head>
<script src="./js/live2dcubismcore.min.js"></script>
<script src="./js/live2d.min.js"></script>
<script src="./js/pixi.min.js"></script>

<!-- if only Cubism 4 support-->
<script src="./js/cubism4.min.js"></script>

<script src="./js/jquery-3.1.1.min.js"></script>

<script src="https://unpkg.com/axios/dist/axios.min.js"></script>

</head>

<body>
<canvas id=canvas></canvas>

<div id="control">

  <button id="play">测试音频</button> 
  <br />

  <label>数字人模型</label>
 <select id="model_list"></select> <button id="update_model">更新模型</button>
  <br />
  <label>语音接口地址</label>
  <input type="search" id="apiurl" style="width:200px;" value="http://127.0.0.1:9880" >
  <br />
  <label>推理文本语言种类</label>
  <input type="search" id="text_lang" style="width:200px;" value="zh" >
  <br />
  <label>参考音频</label>
  <input type="search" id="ref_audio_path" style="width:200px;" value="./Keira.wav" >
  <br />
  <label>参考音频文本</label>
  <input type="search" id="prompt_text" style="width:300px;" value="光动嘴不如亲自做给你看,等我一下呀" >
  <br />
  <label>参考音频文本语种</label>
  <input type="search" id="prompt_lang" style="width:200px;" value="zh" >
  <br />
  <label>切分方式</label>
  <input type="search" id="text_split_method" style="width:200px;" value="cut5" >
  <br />
  <label>语速</label>
  <input type="search" id="speed_factor" style="width:200px;" value="1.0" >
  <br />

  <br />

  <textarea id="text" style="width:400px;height:300px;">神经网络是通过假设的因素去“猜”稀疏矩阵的空缺数据，猜出来之后，再通过反向传播的逆运算来反推稀疏矩阵已存在的数据是否正确，从而判断“猜”出来的数据是否正确。这就是用来做数据预测的矩阵分解算法：通俗地讲，跟算命差不多，但是基于数学原理，如果通过反推证明针对一个人的算命策略都是对的，那么就把这套流程应用到其他人身上。</textarea>

  <br /><br />

  <button id="start">开始推理</button> <button id="stop">停止讲话</button> <button id="start_stream" style="display:none;">流式推理</button>



</div>

<script type="text/javascript">

// 数字人模型
var cubism4Model = './models/<%=model_path%>/<%=model_path%>.model3.json';

var selected_model = '<%-model_path%>';


var model_list = '<%-model_list%>';
model_list = JSON.parse(model_list);


var $select = $("#model_list");
$select.empty(); // 清空旧选项

// 遍历新选项列表并添加到select元素中
$.each(model_list, function(index, value) {

  if (value==selected_model){

    $select.append($("<option selected></option>").attr("value", value).text(value));

  }else{

    $select.append($("<option></option>").attr("value", value).text(value));

  }

});




// const cubism4Model = "./Hiyori/Hiyori.model3.json";

// const cubism4Model = "./March 7th/March 7th.model3.json";

const live2d = PIXI.live2d;


(async function main() {


  const app = new PIXI.Application({
    view: document.getElementById("canvas"),
    autoStart: true,
    resizeTo: window,
    backgroundColor: 0x333333
  });



  var models = await Promise.all([
    live2d.Live2DModel.from(cubism4Model)
  ]);

  models.forEach((model) => {
    app.stage.addChild(model);

    const scaleX = (innerWidth ) / model.width;
    const scaleY = (innerHeight ) / model.height;

    // fit the window
    model.scale.set(Math.min(scaleX, scaleY));

    model.y = innerHeight * 0.1;

    draggable(model);
    // addFrame(model);
    // addHitAreaFrames(model);
   // talk(model)
  });

  const model4 = models[0];


  model4.x = innerWidth  / 2;


  model4.on("hit", (hitAreas) => {
    if (hitAreas.includes("Body")) {
      model4.motion("Tap");
    }

    if (hitAreas.includes("Head")) {
      model4.expression();
    }
  });


  // 更新模型 

  $("#update_model").click(function() {
  
    axios.get('/edit_config',{
  params: {"model_path":$("#model_list").val()}
})
  .then(response => {
    // 处理成功响应
    console.log(response.data);
   location.reload();
  })
  .catch(error => {
    // 处理错误
    console.error(error);
    alert(error);
  });

});


  $("#play").click(function() {
  talk(model4,"./Keira.wav");
});


$("#stop").click(function() {

  model4.stopSpeaking();

});


$("#start").click(function() {

  console.log($("#text").val());


  let text = $("#text").val().trim();


  if(text == ""){

    alert("请输入推理内容");
    return false;

  }

  $("#start").prop("disabled", true);

  axios.defaults.timeout = 300000;

  axios.post($("#apiurl").val(), {
    text_lang: $("#text_lang").val(),
    ref_audio_path: $("#ref_audio_path").val(),
    prompt_lang: $("#prompt_lang").val(),
    prompt_text: $("#prompt_text").val(),
    text_split_method: $("#text_split_method").val(),
    batch_size: 10,
    media_type: 'wav',
    speed_factor: $("#speed_factor").val(),
    text: $("#text").val()
}, {
    responseType: 'arraybuffer'
})
  .then(response => {

    console.log(response.data);
    // 将返回的音频数据转换为Blob对象
    const audioBlob = new Blob([response.data], { type: 'audio/wav' });

    console.log(audioBlob);

    // 创建一个URL对象用于播放音频
    const audioUrl = URL.createObjectURL(audioBlob);

    // 创建一个新的Audio对象并播放音频
    // const audio = new Audio(audioUrl);
    //audio.play();

    talk(model4,audioUrl);

    $("#start").prop("disabled",false);

  })
  .catch(error => {
    console.error('请求接口失败:', error);
    $("#start").prop("disabled",false);
  });


});




$("#start_stream").click(async function() {

console.log($("#text").val());


let text = $("#text").val().trim();


if(text == ""){

  alert("请输入推理内容");
  return false;

}

$("#start_stream").prop("disabled", true);


data = {text_lang: $("#text_lang").val(),
  ref_audio_path: $("#ref_audio_path").val(),
  prompt_lang: $("#prompt_lang").val(),
  prompt_text: $("#prompt_text").val(),
  text_split_method: $("#text_split_method").val(),
  batch_size: 1,
  media_type: 'wav',
  speed_factor: $("#speed_factor").val(),
  text: $("#text").val(),
  streaming_mode:"true"}


  const response = await fetch($("#apiurl").val(), {
method: "POST",
body: JSON.stringify(data),
headers: {
"Content-Type": "application/json"
},
});
const reader = response.body.getReader();
const context = new (window.AudioContext || window.webkitAudioContext)();
const chunks = [];
while (true) {
const { done, value } = await reader.read();
if (done) {
console.log("***********************done");
$("#start_stream").prop("disabled", false);
break;
}
console.log("--------------------value");
console.log(value);
// 将读取到的值添加到数组中
chunks.push(value);
}
// 合并所有读取到的二进制数据
const audioBuffer = new Uint8Array(chunks.reduce((acc, val) => acc.concat(Array.from(val)), []));
// 解码音频数据并播放
context.decodeAudioData(audioBuffer.buffer).then(decodedData => {
const source = context.createBufferSource();
source.buffer = decodedData;
source.connect(context.destination);
source.start(0);
}).catch(error => {
console.error("Error decoding audio data:", error);
});



});



})();


function talk(model,audio){

  
var audio_link =  audio;  //[Optional arg, can be null or empty] [relative or full url path] [mp3 or wav file] "./Keira.wav"
var volume = 1; // [Optional arg, can be null or empty] [0.0 - 1.0]
var expression = 8; // [Optional arg, can be null or empty] [index|name of expression]
var resetExpression = true; // [Optional arg, can be null or empty] [true|false] [default: true] [if true, expression will be reset to default after animation is over]
var crossOrigin = "anonymous"; // [Optional arg, to use not same-origin audios] [DEFAULT: null]

model.speak(audio_link, {volume: volume, expression:expression, resetExpression:resetExpression, crossOrigin: crossOrigin})

// Or if you want to keep some things default
model.speak(audio_link)
model.speak(audio_link, {volume: volume})
model.speak(audio_link, {expression:expression, resetExpression:resetExpression})



}




function draggable(model) {
  model.buttonMode = true;
  model.on("pointerdown", (e) => {
    model.dragging = true;
    model._pointerX = e.data.global.x - model.x;
    model._pointerY = e.data.global.y - model.y;
  });
  model.on("pointermove", (e) => {
    if (model.dragging) {
      model.position.x = e.data.global.x - model._pointerX;
      model.position.y = e.data.global.y - model._pointerY;
    }
  });
  model.on("pointerupoutside", () => (model.dragging = false));
  model.on("pointerup", () => (model.dragging = false));
}

function addFrame(model) {
  const foreground = PIXI.Sprite.from(PIXI.Texture.WHITE);
  foreground.width = model.internalModel.width;
  foreground.height = model.internalModel.height;
  foreground.alpha = 0.2;

  model.addChild(foreground);

  checkbox("Model Frames", (checked) => (foreground.visible = checked));
}

// function addHitAreaFrames(model) {
//   const hitAreaFrames = new live2d.HitAreaFrames();
//   hitAreaFrames.visible = true;
//   model.addChild(hitAreaFrames);

//   //checkbox("Hit Area Frames", (checked) => (hitAreaFrames.visible = checked));
// }

function checkbox(name, onChange) {
  const id = name.replace(/\W/g, "").toLowerCase();

  let checkbox = document.getElementById(id);

  if (!checkbox) {
    const p = document.createElement("p");
    p.innerHTML = `<input type="checkbox" id="${id}"> <label for="${id}">${name}</label>`;

    document.getElementById("control").appendChild(p);
    checkbox = p.firstChild;
  }

  checkbox.addEventListener("change", () => {
    onChange(checkbox.checked);
  });

  onChange(checkbox.checked);
}

</script>


<style>
#control{
  position: absolute;
  top:50px;
  left: 50px;
  color: white;
  font-size:18px;

}
</style>

</body>
</html>